{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoCCQbUxIQ2wypPSLKMXtf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Diego-1099/Colabfiles/blob/main/Pr%C3%A1ctica_16_Datos_Duplicados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6n_ZViitw-r",
        "outputId": "6e0d93b3-82a1-40b3-9b97-50199d053301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Ejercicio 01: Datos perdidos.***\n",
        "\n",
        "  1. Carga el conjunto de datos dirty.csv y verifica que su carga sea correcta.\n",
        "  2. Imprime la cantidad de datos perdidos que tiene el conjunto de datos.\n",
        "  3. Calcula la media de las columna Calories.\n",
        "  4. Aplica imputación por promedio (mean) en la columna Calories.\n",
        "  5. Calcula de nuevo la media de la columna Calories después  de que has imputado."
      ],
      "metadata": {
        "id": "U4A1kKPIudHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/ClassFiles/dirtydata.csv')\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Cantidad de datos perdidos:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print('----------------------------------------------------------------------------')\n",
        "\n",
        "Media_Calorias = df['Calories'].mean()\n",
        "print(\"Media de la columna 'Calories':\", Media_Calorias)\n",
        "\n",
        "print('----------------------------------------------------------------------------')\n",
        "\n",
        "df['Calories'] = df['Calories'].fillna(Media_Calorias)\n",
        "\n",
        "Media_Calorias_Imputada = round(df['Calories'].mean(), 2)\n",
        "print(\"Media de la columna 'Calories' después de la imputación:\", Media_Calorias_Imputada)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "mzaHNUZ3ucUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Ejercicio 02. Duplicidad Parcial una columna: Contar y Filtrar los registros duplicados en Duration.***\n",
        "\n",
        "  1. Carga el documento de datos dirty.csv y verifica que su carga sea correcta.\n",
        "  2. Cuenta la cantidad de registros duplicados utilizando solo la información de columna Duration e imprime.\n",
        "  3. Utiliza value.counts() e imprime la cantidad de registros que hay por cada valor único.\n",
        "  4. Filtra los datos y obten los registros sin duplicados."
      ],
      "metadata": {
        "id": "_S8GWUQeNltu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('----------------------------------------------------------------------------')\n",
        "Duplicados_Duration = df['Duration'].duplicated().sum()\n",
        "print(\"Cantidad de registros duplicados en 'Duration':\", Duplicados_Duration)\n",
        "\n",
        "print('----------------------------------------------------------------------------')\n",
        "print(\"Cantidad de registros por cada valor único en 'Duration':\")\n",
        "print(df['Duration'].value_counts())\n",
        "\n",
        "print('----------------------------------------------------------------------------')\n",
        "Registros_sin_Duplicados = df.drop_duplicates(subset = 'Duration')\n",
        "print('Registros sin duplicados:')\n",
        "print(Registros_sin_Duplicados)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "UpxEaBpIOXWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Ejercicio 03. Duplicidad Parcial Dos Columnas: Contar y Filtrar los registros duplicados en Pulse y MaxPulse.***\n",
        "\n",
        "  1. Carga el documento de datos dirty.csv y verifica que su carga sea correcta.\n",
        "  2. Cuenta la cantidad de registros duplicados utilizando la información de las columnas Pulse y MaxPulse e imprime.\n",
        "  3. Utiliza value.counts() e imprime la cantidad de registros que hay por cada valor único.\n",
        "  4. Filtra los datos y obten los registros cuando keep = 'last'."
      ],
      "metadata": {
        "id": "lmNbEjWiSjnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('----------------------------------------------------------------------------')\n",
        "Pulse_Maxpulse_Duplicados = df.duplicated(subset = ['Pulse', 'Maxpulse']).sum()\n",
        "print(\"Cantidad de registros duplicados de las columnas 'Pulse' y 'Maxpulse':\", Pulse_Maxpulse_Duplicados)\n",
        "\n",
        "print('----------------------------------------------------------------------------')\n",
        "print(\"Cantidad de registros por cada valor único en 'Pulse' y 'Maxpulse':\")\n",
        "print(df[['Pulse', 'Maxpulse']].value_counts())\n",
        "\n",
        "print('----------------------------------------------------------------------------')\n",
        "Pulse_Maxpulse_sin_Duplicados = df.drop_duplicates(subset = ['Pulse', 'Maxpulse'], keep = 'last')\n",
        "print('Registros sin duplicados de las columnas \"Pulse\" y \"Maxpulse\":')\n",
        "print(Pulse_Maxpulse_sin_Duplicados)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "tHd7PWVaTKwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Ejercicio 04. Duplicidad Total o Exacta: Contar y Filtrar los registros duplicados.***\n",
        "\n",
        "  1. Carga el documento de datos dirty.csv y verifica que su carga sea correcta.\n",
        "  2. Cuenta la cantidad de registros duplicados exactos (todas las columnas).\n",
        "  3. Utiliza sum() e imprime la cantidad de registros con duplicidad exacta.\n",
        "  4. Filtra los datos y obten los registros cuando keep = 'last'."
      ],
      "metadata": {
        "id": "_25naVLtVEFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('----------------------------------------------------------------------------')\n",
        "df_duplicados_exactos = df.duplicated().sum()\n",
        "print('Cantidad de registros duplicados exactos:', df_duplicados_exactos)\n",
        "\n",
        "print('----------------------------------------------------------------------------')\n",
        "df_sin_duplicados_exactos = df.drop_duplicates(keep = 'last')\n",
        "print('Registros sin duplicados exactos:')\n",
        "print(df_sin_duplicados_exactos)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "RpDoJF1uVgD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Ejercicio 05: Cálculo de la media con duplicados y sin duplicados.***\n",
        "\n",
        "  1. Carga el documento de datos dirty.csv y verifica que su carga sea correcta.\n",
        "  2. Cálcula e imprime la media de las columnas Pulse y Maxpulse.\n",
        "  3. Identifica los valores duplicados en las columnas Pulse y Maxpulse (Duplicidad Parcial) y elimina los registros repetidos. Quédate con las últimas ocurrencias.\n",
        "  4. Utiliza el conjunto anterior sin datos duplicados (recuerda que solo quedaron las últimas ocurrencias de los datos) y calcula la media de las columnas Pulse y Maxpulse."
      ],
      "metadata": {
        "id": "U7VryPSpW2Zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('----------------------------------------------------------------------------')\n",
        "Media_Pulse = df['Pulse'].mean()\n",
        "Media_Maxpulse = df['Maxpulse'].mean()\n",
        "print(\"Media de la columna 'Pulse' con duplicados:\", Media_Pulse)\n",
        "print(\"Media de la columna 'Maxpulse' con duplicados:\", Media_Maxpulse)\n",
        "\n",
        "\n",
        "print('----------------------------------------------------------------------------')\n",
        "Pulse_Maxpulse_Datos_sin_Duplicados = df.drop_duplicates(subset = ['Pulse', 'Maxpulse'], keep = 'last')\n",
        "Media_Pulse_sin_Duplicados = round(Pulse_Maxpulse_Datos_sin_Duplicados['Pulse'].mean(), 2)\n",
        "Media_Maxpulse_sin_Duplicados = round(Pulse_Maxpulse_Datos_sin_Duplicados['Maxpulse'].mean(), 2)\n",
        "print(\"Media de la columna 'Pulse' sin duplicados:\", Media_Pulse_sin_Duplicados)\n",
        "print(\"Media de la columna 'Maxpulse' sin duplicados:\", Media_Maxpulse_sin_Duplicados)\n",
        "\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "koiztf40XsCM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}